- Q1
  DB::Exception: Cannot create table from metadata file /data/clickhouse/metadata/default/dwd_test.sql, error: DB::Exception: The local set of parts of table default.dwd_test doesnâ€™t look like the set of parts in ZooKeeper: 65.88 million rows of 85.04 million total rows in filesystem are suspicious. There are 545 unexpected parts with 65883643 rows (191 of them is not just-written with 65883643 rows), 0 missing parts (with 0 blocks).

- A1
  è¿™æ˜¯ç”±äºtruncateã€alterç­‰ddlè¯­å¥ç”¨äº†on clusterï¼Œå¶å°”å¯¼è‡´zookeeperåŒæ­¥å¼‚å¸¸ã€‚è§£å†³æ–¹æ³•1ï¼šåˆ é™¤æœ‰é—®é¢˜èŠ‚ç‚¹çš„æœ¬åœ°è¡¨æ•°æ® rm -r /data/clickhouse/data/default/dwd_testï¼Œå†é‡æ–°å¯åŠ¨CKï¼Œå‰¯æœ¬ä¼šè‡ªåŠ¨é‡æ–°åŒæ­¥è¯¥è¡¨æ•°æ®ã€‚(å¦‚æœæ²¡æœ‰å‰¯æœ¬è¯·ä¸è¦ä½¿ç”¨æ­¤æ–¹æ³•ã€‚)
  è§£å†³æ–¹æ³•2ï¼šå‘½ä»¤è¡Œæ‰§è¡Œsudo -u clickhouse touch /data/clickhouse/flags/force_restore_data ç„¶åæ‰‹åŠ¨æ¢å¤æœ‰é—®é¢˜çš„partition

- Q2
  Connected to ClickHouse server version 20.3.8 revision 54433.
  Poco::Exception. Code: 1000, e.code() = 13, e.displayText() = Access to file denied: /home/qspace/.clickhouse-client-history (version 20.3.8.53 (official build))

- A2

  åˆ›å»ºè¯¥æ–‡ä»¶ã€å¹¶è®¾ç½®å¼€æ”¾æƒé™ã€‚
  chown clickhouse:clickhouse /home/qspace/.clickhouse-client-history (æ²¡æœ‰åˆ™åˆ›å»º)

- Q3
  Application: DB::Exception: Listen [::]:8124 failed: Poco::Exception. Code: 1000, e.code() = 0, e.displayText() = DNS error: EAI: Address family for hostname not supported (version 20.5.2.7 (official build))

- A3
  æœ¬æœºæ²¡æœ‰å¼€æ”¾ipv6ï¼Œåªèƒ½å¯¹ipv4ç”Ÿæ•ˆã€‚åœ¨/etc/click-house/config.xmlä¸­ï¼ŒæŠŠ<listen_host> æ”¹æˆ0.0.0.0 æˆ–è€… ::

- Q4
  Code: 32, e.displayText() = DB::Exception: Received from hadoop8:9900. DB::Exception: Attempt to read after eof: Cannot parse Int32 from String, because value is too short. (version 20.3.8.53 (official build))
  å­—ç¬¦ä¸²è½¬æ•°å­—å¼‚å¸¸ï¼Œæœ‰äº›ä¸ºç©ºæˆ–è€…éæ•°å­—çš„å­—ç¬¦å¯¼è‡´è½¬æ¢å¤±è´¥

- A4
  ä½¿ç”¨toUInt64OrZeroå‡½æ•°ã€è½¬æ¢å¤±è´¥åˆ™ä¸º0ã€‚

- Q5
  Application: DB::Exception: Suspiciously many (125) broken parts to remove.: Cannot attach table `default`.`test`
  Code: 231. DB::Exception: Received from ck10:9000. DB::Exception: Suspiciously many (125) broken parts to removeâ€¦

- A5
  å› ä¸ºå†™å…¥æ•°æ®é€ æˆçš„å…ƒæ•°æ®å’Œæ•°æ®ä¸ä¸€è‡´é—®é¢˜ã€‚å…ˆåˆ é™¤ç£ç›˜æ•°æ®ã€å†é‡å¯èŠ‚ç‚¹åˆ é™¤æœ¬åœ°è¡¨ï¼Œå¦‚æœæ˜¯å¤åˆ¶è¡¨å†ä¸Šzookeeperåˆ é™¤å‰¯æœ¬ï¼Œç„¶åé‡æ–°å»ºè¡¨ã€‚å¤åˆ¶è¡¨çš„è¯æ•°æ®ä¼šåŒæ­¥å…¶ä»–å‰¯æœ¬çš„ã€‚

- Q6
  Cannot execute replicated DDL query on leader.

- A6
  ç”±äºåˆ†å¸ƒå¼ddlè¯­å¥æ¯”è¾ƒè€—æ—¶ä¼šè¶…æ—¶å“åº”ã€æ”¹ä¸ºæœ¬åœ°æ‰§è¡Œæˆ–è€…å‡å°‘ä½œç”¨çš„æ•°æ®èŒƒå›´ã€‚å¦‚ALTERã€OPTIMIZEå…¨è¡¨æ”¹ä¸ºå…·ä½“çš„partition.

- Q7
  Code: 76. DB::Exception: Received from 0.0.0.0:9900. DB::Exception: Cannot open file /data/clickhouse/data/default/test/tmp_insert_20200523_55575_55575_0/f0560_deep_conversion_optimization_goal.mrk2, errno: 24, strerror: Too many open files.

- A7
  ä¿®æ”¹/etc/security/limits.conf æ·»åŠ ï¼š
  clickhouse soft nofile 262144
  clickhouse hard nofile 262144
  ä½¿ç”¨ulimit -n æŸ¥è¯¢ã€çœ‹åˆ°çš„æ˜¯æ‰€æœ‰ç”¨æˆ·å¯æ‰“å¼€çš„æ€»æ•°ï¼Œè€Œckèƒ½æ‰“å¼€çš„å¤§å°åªæ˜¯ç³»ç»Ÿçš„é»˜è®¤å€¼ï¼Œæ‰€ä»¥ä¸è¦è¢«è¿™ä¸ªå‘½ä»¤å¹²æ‰°ï¼Œé‡å¯ckåã€è·å–ckçš„è¿›ç¨‹ã€å†é€šè¿‡`cat /proc/${pid}/limits |grep open` ï¼Œåˆ¤æ–­é…ç½®æ˜¯å¦ç”Ÿæ•ˆ







# 1. clickhouseä¿®æ”¹å­—æ®µç±»å‹

å½“åˆ«äººå¾€è¡¨ä¸­æ’å…¥æ•°æ®ï¼Œä¹Ÿå°±æ˜¯å¯¹å­—æ®µè¿›è¡Œæ“ä½œæ—¶ï¼Œæ˜¯ä¸èƒ½ä¿®æ”¹å­—æ®µç±»å‹çš„

æ­¤æ—¶è‹¥è¦ä¿®æ”¹å­—æ®µç±»å‹ï¼Œéœ€è¦å…ˆdropæ‰è¯¥å­—æ®µï¼Œå†è¿›è¡Œaddï¼Œå¦‚æœå•çº¯ä½¿ç”¨modifyæ˜¯ä¸ä¼šä¿®æ”¹æˆåŠŸçš„ã€‚

ğŸŒ°ï¼š

åŸå§‹ col1 ç±»å‹æ˜¯ stringï¼Œæ­¤æ—¶è‹¥è¦ä¿®æ”¹ä¸ºint32:

> alter table base.table ON CLUSTER *** modify column col1 Int32;

butï¼šå¦‚æœæ­¤åˆ—ä¸€ç›´åœ¨è¿›è¡Œè¢«ä¿®æ”¹ï¼Œæ¯”å¦‚æ’å…¥æ•°æ®ï¼Œåˆ™ä¼šæŠ¥é”™ï¼š

Exception: Received from 10.2.29.1:9000 . DB::Exception: There was an error on [10.2.29.2:9000] : Code: 439, [e.displayText](https://blog.csdn.net/yuanyuanxingxing/article/details/e.displayText) () = DB::Exception: Cannot schedule a task (version [19.9.2.4](https://blog.csdn.net/yuanyuanxingxing/article/details/19.9.2.4) (official build)).

 æ­¤æ—¶åº”è¯¥å…ˆåˆ é™¤æ­¤åˆ—ï¼Œå†é‡æ–°addåˆ—åŠæ•°æ®ç±»å‹

> ALTER TABLE base.table ON CLUSTER *** DROP COLUMN col1;  --dropåˆ—
>
> alter table base.table ON CLUSTER *** add column col1 Int32; --addåˆ—

#  2. clickhouseå»ºè¡¨ï¼Œå¯¼å…¥CSVæ•°æ®

å¦‚æœè¡¨ä¸­æ²¡æœ‰æ—¶é—´æˆ³ï¼Œä¹Ÿæ²¡æœ‰keyï¼Œåˆ™å¯ä»¥ä½¿ç”¨ **ENGINE = TinyLog;**

> CREATE TABLE defult.industry_tag (`industry` String, `tag` String) ENGINE = TinyLog;

å¯¼å…¥CSVæ•°æ®æ—¶ï¼Œå¦‚æœcsvè¡¨ä¸­æœ‰ç›¸åº”çš„åˆ—æ˜ï¼Œåˆ™éœ€è¦æŒ‡æ˜ä½¿ç”¨ **FORMAT CSVWithNamesï¼Œ**å¦‚æœcsvè¡¨æ²¡æœ‰åˆ—æ˜ï¼Œåˆ™ä½¿ç”¨ **FORMAT CSV**

ğŸŒ°ï¼š

## 1. å€˜è‹¥CSVé•¿è¿™æ ·ï¼š

>  industry,tag
>  ç¤¾äº¤,QQ
>  ç¤¾äº¤,WeChat
>  ç¤¾äº¤,é™Œé™Œ

ä½¿ç”¨å¦‚ä¸‹ä»£ç å¯¼å…¥åˆ°clickhouse 

> cat industry-tag.csv | clickhouse-client -h 10.2.**.* --password *** -m --query="INSERT INTO defult.industry_tag FORMAT CSVWithNames";

## 2. å€˜è‹¥CSVé•¿è¿™æ ·ï¼š

> ç¤¾äº¤,QQ
> ç¤¾äº¤,WeChat
> ç¤¾äº¤,é™Œé™Œ

ä½¿ç”¨å¦‚ä¸‹ä»£ç å¯¼å…¥åˆ°clickhouse 

> cat industry-tag.csv | clickhouse-client -h 10.2.**.* --password *** -m --query="INSERT INTO defult.industry_tag FORMAT CSV";

# 3. è¦è¯¥å­—æ®µç±»å‹ï¼Œéœ€å…ˆæ”¹åº•å±‚è¡¨ï¼Œå†æ”¹åˆ†å¸ƒå¼è¡¨ï¼Œå¦åˆ™æŠ¥é”™

# 4. å»ºåˆ†å¸ƒå¼è¡¨

> ```html
> CREATE TABLE IF NOT EXISTS database.test_dist_table(
> 
> 
> 
> event_date Date MATERIALIZED toDate(now())
> 
> 
> 
> , pv Int32
> 
> 
> 
> , click Int32
> 
> 
> 
> , download Int32
> 
> 
> 
> , install Int32
> 
> 
> 
> , active Int32
> 
> 
> 
> , request Int32
> 
> 
> 
> )  ENGINE = Distributed(cluster_name***, database, test_table, rand());  --test_tableä¸ºéåˆ†å¸ƒå¼åº•å±‚è¡¨
> ```