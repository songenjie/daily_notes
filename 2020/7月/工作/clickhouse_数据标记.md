MergeTree: 一本书

Primary.idx: 一级索引好比这本书的一级章节目录

.bin ：整个书的问题

.mrk ：数据标记，为一级章节目录和具体的文字之间建立关联



- .mrk ：记录，目的 查询某段文字所在页码和第几行 说白就是一级索引和文件的关联（桥梁）

1. 一级章节对应的页码位置
2. 一段文字在某一页中的起始位置。 



![数据读取关系图](https://github.com/songenjie/daily_notes/blob/master/source/clickhouse_存储关系图.jpg) 

- 特征

1. 首先第多少行就是第多少个字节，说明当前列 就是一个Uint8 (1B*8192=8192B,64Kb=65536B=8*8192B)
2. Index_granularity 8192



| .mrk           | .mrk                                                         | .mrk                 | 当前行所在偏移大小 |            | .binhead   | .binhead   |
| -------------- | ------------------------------------------------------------ | -------------------- | ------------------ | ---------- | ---------- | ---------- |
| 未压缩文件编号 | 压缩块偏移量                                                 | 未/解压缩块偏移量 行 | 偏移大小           | 压缩块编号 | 压缩块大小 | 未压缩大小 |
| 0              | 0                                                            | 0                    | 0                  | 0          |            |            |
| 1              | 0                                                            | 8192                 | 8192               | 0          |            |            |
| 2              | 0                                                            | 16384                | 16384              | 0          |            |            |
| 3              | 0                                                            | 24576                | 24576              | 0          |            |            |
| 4              | 0                                                            | 32768                | 32768              | 0          |            |            |
| 5              | 0                                                            | 40960                | 40960              | 0          |            |            |
| 6              | 0                                                            | 49152                | 49152              | 0          |            |            |
| 7              | 0                                                            | 57344                | 57344              | 0          | 12000      | 65535      |
| 8              | 12016                                                        | 65536/0              | 65536              | 1          | 14661      | 65535      |
| 9              | 12016=8(前压缩块头)+12000(前压缩块大小)+8(当前压缩块的头大小) | 8192                 | 65536+8192         | 1          |            |            |
|                | 12016                                                        | ...                  |                    | 1          |            |            |
|                | ...                                                          |                      |                    |            |            |            |
|                | 1402429                                                      |                      |                    |            |            |            |



一个压缩块，是最小解压单元 

12016+8192 找编号为1的压缩块的地8192行的数据

整个字段比较凑巧  



- 数据块大小有 上下线设置 64k~1M  page block

min_compress_block_size(65535 默认 16k) ~ max_compress_block_size(1048576 1M) ,最终压缩的大小，和一个间隔(index_granularity) 内实际大小有关



- 每一批 默认每次取 8192行数据，一批数据未压缩大小设置为size,写入过程为

1. 单个批次数据 size<64KB，如果单个批次数据小于64KB,则继续获取下一批数据，直至累积到>64Kb,直接生成下一个压缩数据块
2. 单个批次64Kb<size<=1MB,直接生成下一个压缩数据块
3. size>1MB,首先会按照1MB截断并生成下一个压缩数据块，剩余数据，依照上述规则执行





- 特征

1. 首先第多少行就是第多少个字节，说明当前列 就是一个Uint16 (2B *8192=16384B,64Kb=65536B= 4* * 16384B)
2. Index_granularity 8192
3. 



| .mrk           | .mrk                                                         | .mrk                 | 当前行所在字节大小 |            | .binhead   | .binhead   |
| -------------- | ------------------------------------------------------------ | -------------------- | ------------------ | ---------- | ---------- | ---------- |
| 未压缩文件编号 | 压缩块偏移量                                                 | 未/解压缩块偏移量 行 | 偏移大小           | 压缩块编号 | 压缩块大小 | 未压缩大小 |
| 0              | 0                                                            | 0                    | 0                  | 0          |            |            |
| 1              | 0                                                            | 8192                 | 16384              | 0          |            |            |
| 2              | 0                                                            | 16384                | 32768              | 0          |            |            |
| 3              | 0                                                            | 24576                | 49152              | 0          | 12000      | 65525      |
| 4              | 12016=8(前压缩块头)+12000(前压缩块大小)+8(当前压缩块的头大小) | 32768                | 65536              | 1          | 14661      | 65535      |
| 5              | 12016                                                        | 40960                | 63336+16384        | 1          |            |            |
| 6              | 12016                                                        | 49152                |                    | 1          |            |            |
| 7              | 12016                                                        | 57344                |                    | 1          | 14661      | 65535      |
| 8              | *=8+12000+8+14661+8                                          | 65536/0              |                    | 2          | *          | 65535      |
| 9              | *=8+12000+8+14661+8                                          | 8192                 |                    | 2          |            |            |



分区 partition + 索引 primary key + 标记 ark + 压缩 bin,

![索引和标记的关系](/source/clickhouse_索引_标记关系.jpg)



索引和标记的对齐的，标记与压缩块根据当前字段长度的不同，会出现 多对一，和一对一，一对多的情况

上面的例子就都是多对一的情况

 

这取决于 该列 字段的大小  1bytes 8 bytes  8bytes



![多对一](/source/clickhouse_索引_压缩块_多对一.jpg)

![一对一](/source/clickhouse_索引_压缩块_一对一.jpg)

![一对多](/source/clickhouse_索引_压缩块_一对多.jpg)





Clickhouse 中最强大的表引擎当属 MergeTree （合并树）引擎及该系列（*MergeTree）中的其他引擎。MergeTree 引擎系列的基本理念如下。当你有巨量数据要插入到表中，你要高效地一批批写入数据片段，并希望这些数据片段在后台按照一定规则合并。相比在插入时不断修改（重写）数据进存储，这种策略会高效很多。主要优势：

- 存储的数据按主键排序。
  这让你可以创建一个用于快速检索数据的小稀疏索引。
- 允许使用分区，如果指定了 分区键 的话。
  在相同数据集和相同结果集的情况下 ClickHouse 中某些带分区的操作会比普通操作更快。查询中指定了分区键时 ClickHouse 会自动截取分区数据。这也有效增加了查询性能。
- 支持数据副本。
  ReplicatedMergeTree 系列的表便是用于此。

以官网用例来看。我们以 (CounterID, Date) 以主键。排序好的索引的图示会是下面这样：

```bash
全部数据  :      [-------------------------------------------------------------------------]
CounterID:      [aaaaaaaaaaaaaaaaaabbbbcdeeeeeeeeeeeeefgggggggghhhhhhhhhiiiiiiiiikllllllll]
Date:           [1111111222222233331233211111222222333211111112122222223111112223311122333]
标记:            |      |      |      |      |      |      |      |      |      |      |
                a,1    a,2    a,3    b,3    e,2    e,3    g,1    h,2    i,1    i,3    l,3
标记号:          0      1      2      3      4      5      6      7      8      9      10
```

