:sort



sort u





换行替换



%s/xx/\r/g







### Why Doris

对我们用户来说，**Doris 的优点是功能强大，易用性好**。 功能强大指可以满足我们用户的需求，易用性好主要指 **兼容 Mysql 协议和语法，以及 Online Schema Change**。 兼容 Mysql 协议和语法让用户的学习成本和开发成本很低， Online Schema Change 也是一个很吸引人的 feature，因为在业务快速发展和频繁迭代的情况下，Schema 变更会是一个高频的操作。

对我们平台侧来说，Doris 的优点是**易运维，易扩展和高可用**：

- 易运维指 Doris 无外部系统依赖，部署和配置都很简单。
- 易扩展指 Doris 可以一键加减节点，并自动均衡数据。
- 高可用值 Dors 的 FE 和 BE 都可以容忍少数节点挂掉





|      类别      |                   Doris                   |      Clickhouse      |                             备注                             |
| :------------: | :---------------------------------------: | :------------------: | :----------------------------------------------------------: |
|      类别      |                   Doris                   |      Clickhouse      |                             备注                             |
|    总体架构    |            Share-Nothing + MPP            |         相同         |          方便横向扩展添加节点，并行可以提高处理速度          |
|                |                   列存                    |         相同         |           查询少量列时减少扫描数据量，可以支持压缩           |
|                |           内置分布式协议类似ZAB           |    依赖Zookeeper     |               Master/Follower/Observer节点类型               |
|                |              事务和MVCC机制               |   100万以内原子性    |                      可以保证数据一致性                      |
|                |               支持数据规模                |    单集群 < 10PB     |                        单集群 < 10 PB                        |
|                |                                           |                      |                                                              |
|    导入方式    |          从Kafka导入数据（内置）          |       内置支持       |                  分钟级(1-15分钟)，配置即可                  |
|                |         从HDFS上导入数据（内置）          | 外部通过HTTP接口导入 |                 离线数据或历史数据，配置即可                 |
|                |           分布式Spark/Flink导入           | 外部通过HTTP接口导入 |                         业务方写代码                         |
|                |               本地JDBC/HTTP               |         支持         |           本地代码导入，JDBC少数据量，HTTP大数据量           |
|                |        INSERT INTO ... SELECT ...         |         支持         |          可以把一张维度多的表汇总成另一张维度少的表          |
|                |               数据格式支持                |                      |                       orc/parquet/json                       |
|                |                                           |                      |                                                              |
|    存储架构    |               一级范围分区                |         支持         |                     一般日期天/周/月范围                     |
|                |               二级Hash分桶                |         支持         |                     按ID等分布均匀的字段                     |
|                |                支持多副本                 |         支持         |                 单个节点故障不影响写入和查询                 |
|                |              结构化数据支持               |   结构化、半结构化   |                不支持半结构化/嵌套的数据类型                 |
|                |               压缩格式支持                |      LZ4，ZSTD       |                           LZO，LZ4                           |
|                |                 前缀索引                  |       稀疏索引       |                      36个字节的前缀索引                      |
|                |                 物化视图                  |                      |           支持创建常用维度的物化视图，加快查询速度           |
|                | 支持Bitmap索引精确去重支持HLL索引抽样计算 |   不支持Bitmap索引   |                         可以加快查询                         |
|                |             增量数据后台合并              |                      |                       不影响导入和查询                       |
|                |            支持自动分区（TTL）            |         支持         |                可以指定分区策略，自动创建分区                |
|                |               支持类型转换                |                      |     比如Date/DateTime，float/double → decimal，增加长度      |
|                |         变通的数据更新和删除支持          |                      | 更新：用替换的方式，或用变化量的方式求和删除：用软删除和分区重建（需要外部工具支持） |
|                |                 写入性能                  |                      |                 可以并行写，10M/桶（1万条）                  |
|                |                 读写分离                  |                      |                       支持云存储和读取                       |
|                |                                           |                      |                                                              |
|    计算能力    |                 并发能力                  |                      |            QPS 100/台，要看扫描数据量和计算复杂度            |
|                |                 查询时间                  |                      |             TP99 < 100ms - 1S，要看查询数据大小              |
|                |                 编译执行                  |                      |             可以把多个SQL函数编译成一个方法执行              |
|                |                 谓词下推                  |                      |                可以把Where条件下推到扫描节点                 |
|                |              BroadCast Join               |                      |                 小表广播到大表节点上参与计算                 |
|                |                 Hash Join                 |                      |           类似Spark Shuffle，都分发到同一台服务器            |
|                |               Colocate Join               |                      |            相同ID数据在一台服务器，本地Join速度快            |
|                |                自定义函数                 |                      |                  支持UDF/UDAF，暂不支持UDTF                  |
|                |             查询结果整体缓存              |                      |                             支持                             |
|                |              查询按分区缓存               |                      |                           正在进行                           |
|                |                                           |                      |                                                              |
|     扩展性     |             支持JDBC/ODBC协议             |                      |                        支持多种客户端                        |
|                |                兼容标准SQL                |                      |                        扩展了高级写法                        |
|                |                 容器部署                  |                      |                             支持                             |
|                |               外查MySQL的表               |                      |                             支持                             |
|                |                外查ES的表                 |                      |                             支持                             |
|                |              Spark查JD-OLAP               |                      |                             支持                             |
|                |                查Hive的表                 |                      |                           暂不支持                           |
|                |                                           |                      |                                                              |
|     管理性     |              元数据自动同步               |                      |                       方便上下线服务器                       |
|                |               副本自动均衡                |                      |                      节点故障不影响使用                      |
|                |                 数据备份                  |                      |                        支持备份到HDFS                        |
|                |                监控和报警                 |                      |                     较为完善的监控和后台                     |
|                |             多租户和资源隔离              |                      |          按业务分数据库、分账号，但硬件资源无法隔离          |
|                |                                           |                      |                                                              |
| 权限/安全/审计 |                   权限                    |                      |                 数据库用户和权限控制，表级别                 |
|                |                   审计                    |                      |                          有审计日志                          |
|                |                端到端加密                 |                      |                            不支持                            |
|                |                 网络隔离                  |                      |                             暂无                             |
|                |                                           |                      |                                                              |
|    一些局限    |           没有Update/Delete语法           |                      |                       只支持Append操作                       |
|                |            DDL/DML操作后台异步            |                      |         一般很快，系统繁忙时需要等待，或超时后要重试         |
|                |        跨数据中心数据一致性不完善         |                      |                   目前需要业务方双写来保证                   |
|                |                                           |                      |                                                              |



查询 

- 单表查询，Doris查询时间是CK的6倍以上（关闭Cache之后，大概是2-8倍之间）
- 大表关联小表，小表数据量在1000万以下CK性能要好，大于1000万Doris要好 



**单表压测**

选择了2个单表查询的SQL，5-25个并发，200次Query，QPS CK还是比较强



**多表压测**

选择大表关联小表的SQL，小表数据量为137万和1100万，1-16个并发，30次Query，小表137万CK强，小表1100万，Doris表现出色



**导入速度和压缩率**

- Doris导入时间是CK的1.5倍，10G数据CK需要20分钟，Doris需要30分钟
- 数据压缩率，CK是2.6，Doris是2.08，50G数据CK 19.2G，Doris 24G



**其他方面**

- MPP、列存、压缩、索引、分区、分片两者都支持
- 导入事务、批量更新/删除、Kafka/HDFS/MySQL导入两者都支持 
- CK集群管理、副本均衡、建表语句、查询SQL兼容上稍有不足 
- CK数据类型、分区TTL、格式支持、客户端工具、测试工具、社区发展方面稍强 



开发，代码维护

Clickhouse> doris



数据类型

doris> clickhouse 



1 doris 多列索引的支持 没有 clickhouse 好，doris 前36bytes

2 导入顺序，是实际的表字段数据 ，clickhouse有 order  by ,重新规划，doris 表的列，必须和primary key 顺序一致

3 doris 有 多列rollup(定制化 kylin cube),空间换时间

4 TTL clickhouse有 行 列 分区级别不同的ttl



1. 没有完整的事务支持
2. 缺少高频率、低延迟的修改或删除已存在数据的能力，仅能用于批量删除或修改数据。





### CK为啥这么高效？

- 答案就是全表扫描

- 那么问题来了，为什么全表扫描性能还这么快？

- 在计算机系统里，有一个概念叫SIMD，即单指令流多数据流（Single Instruction Multiple Data），是一种采用一个控制器来控制多个处理器，同时对一组数据（又称“数据向量”）中的每一个分别执行相同的操作从而实现空间上的并行性的技术。这种方式，极大的提升了数据的查询效率，因此可以做到即使是全表扫，也能达到很高的性能。

- 关于CK的高效

  1. CK不能简单看成一个数据库，它用了大量的并行计算方式，把单机性能压榨到极限

  - Hadoop生态非常依赖集群的数量，通过scale out的方式，让计算发生在本地，分而治之，通过M后再R的方式，提高执行效率。
  - 在实际的使用过程中，很明显的感觉到，10台规模的Hadoop和100台规模的Hadoop无法同日而语，原因就在于数据打的不够散
  - CK的方式，可以理解为，通过列式存储的方式，本身查询的时候就做了Map化，再对每一列做操作的时候，又使用向量化操作，等于是又增加了并发，因此，单机效率极高
  - 理解有误请指正